library(tidyverse)
library(tidymodels)
library(here)
library(readr)
library(dplyr)
# Handle common conflicts
tidymodels_prefer()
# Load datasets ----
data19 <- read.csv(here("data19/initial_cleaning_dataset.csv"))
data20 <- read.csv(here("data20/initial_cleaning_dataset.csv"))
data21 <- read.csv(here("data21/initial_cleaning_dataset.csv"))
data22 <- read.csv(here("data22/initial_cleaning_dataset.csv"))
data23 <- read.csv(here("data23/initial_cleaning_dataset.csv"))
# Rename columns using the rename dictionary
rename_dict <- list(
"EDUC_A" = "EDUCP_A",
"MAXEDUC_A" = "MAXEDUCP_A",
"EMPWRKLSWK_A" = "EMPWRKLSW1_A",
"LSATIS4R_A" = "LSATIS4_A"
)
rename_variables <- function(data, rename_dict) {
colnames(data) <- sapply(colnames(data), function(col) {
if (col %in% names(rename_dict)) {
rename_dict[[col]]
} else {
col
}
})
return(data)
}
# Rename columns across datasets
data19 <- rename_variables(data19, rename_dict)
data20 <- rename_variables(data20, rename_dict)
data21 <- rename_variables(data21, rename_dict)
data22 <- rename_variables(data22, rename_dict)
data23 <- rename_variables(data23, rename_dict)
# Create a unified list of all columns
all_vars <- unique(unlist(lapply(list(data19, data20, data21, data22, data23), colnames)))
# Function to add missing columns
add_missing_cols <- function(data, all_vars) {
missing_vars <- setdiff(all_vars, colnames(data))
for (var in missing_vars) {
data[[var]] <- NA  # Add missing columns as NA
}
return(data)
}
# Apply function to all datasets
data19 <- add_missing_cols(data19, all_vars)
data20 <- add_missing_cols(data20, all_vars)
data21 <- add_missing_cols(data21, all_vars)
data22 <- add_missing_cols(data22, all_vars)
data23 <- add_missing_cols(data23, all_vars)
# Print shared and unique columns across datasets
shared_columns <- Reduce(intersect, list(colnames(data19), colnames(data20), colnames(data21), colnames(data22), colnames(data23)))
unique_columns <- lapply(list(data19, data20, data21, data22, data23), function(data) setdiff(colnames(data), shared_columns))
cat("Shared Columns:\n", paste(shared_columns, collapse = ", "), "\n\n")
cat("Unique Columns:\n")
print(unique_columns)
# Create a unified list of all columns
all_vars <- unique(unlist(lapply(list(data19, data20, data21, data22, data23), colnames)))
# Add year column ----
data19$year <- 2019
data20$year <- 2020
data21$year <- 2021
data22$year <- 2022
data23$year <- 2023
# Combine datasets ----
combined_data <- bind_rows(data19, data20, data21, data22, data23)
combined_data <- combined_data |>
rename(
sex = SEX_A,
urban_rural = URBRRL,
physical_health = PHSTAT_A,
anxiety_freq = ANXFREQ_A,
anxiety_level = ANXLEVEL_A,
depression_freq = DEPFREQ_A,
depression_level = DEPLEVEL_A,
depression_ever = DEPEV_A,
anxiety_ever = ANXEV_A,
spouse_gender = SPOUSESEX_A,
sexual_orientation = ORIENT_A,
nativity_status = NATUSBORN_A,
data_group = group,
region = REGION,
education_level = EDUCP_A,
hypertension_ever = HYPEV_A,
race_category = RACEALLP_A,
years_in_household = HOUYRSLIV_A,
housing_tenure = HOUTENURE_A,
mental_health_therapy = MHTHRPY_A,
max_education_level = MAXEDUCP_A,
employment_last_week = EMPWRKLSW1_A,
not_covered = NOTCOV_A,
age = AGEP_A,
hispanic_ethnicity = HISP_A,
hispanic_and_race = HISPALLP_A,
hispanic_details = HISDETP_A,
marital_status = MARITAL_A,
parent_status = PARSTAT_A,
life_satisfaction = LSATIS4_A,
anxiety_screening = GAD2SCREEN_A,
depression_screening = PHQ2SCREEN_A,
discrimination_1 = DISCRIM1_A,
discrimination_2 = DISCRIM2_A,
discrimination_3 = DISCRIM3_A,
discrimination_4 = DISCRIM4_A,
discrimination_5 = DISCRIM5_A
) |>
mutate(
# binary variables
depression_freq = ifelse(is.na(depression_freq) & depression_ever == "No", 0, depression_freq),
anxiety_freq = ifelse(is.na(anxiety_freq) & depression_ever == "No", 0, anxiety_freq),
anxiety_freq = factor(anxiety_freq, levels = c(0, 1, 2, 3, 4, 5), ordered = TRUE),
depression_freq = factor(depression_freq, levels = c(0, 1, 2, 3, 4, 5), ordered = TRUE),
depression_ever = factor(depression_ever, levels = c(0, 1), labels = c("No", "Yes")),
anxiety_ever = factor(anxiety_ever, levels = c(0, 1), labels = c("No", "Yes")),
hypertension_ever = factor(hypertension_ever, levels = c("No", "Yes")),
mental_health_therapy = factor(mental_health_therapy, levels = c("No", "Yes")),
employment_last_week = factor(employment_last_week, levels = c("No", "Yes")),
not_covered = factor(not_covered, levels = c("Covered", "Not covered")),
anxiety_screening = factor(anxiety_screening, levels = c(0, 1), labels = c("No", "Yes")),
depression_screening = factor(depression_screening, levels = c(0, 1), labels = c("No", "Yes")),
# factor variables - no order necessary
spouse_gender = factor(spouse_gender, levels = c("Male", "Female")),
sexual_orientation = factor(sexual_orientation, levels = c(1, 2, 3, 4), labels = c("GayLesbian", "Straight", "Bisexual", "Other")),
nativity_status = factor(nativity_status, levels = c(1, 2), labels = c("Native-born", "Foreign-born")),
data_group = factor(data_group, levels = c("LGBTQ_NonMigrant", "LGBTQ_Migrant", "Straight_NonMigrant", "Straight_Migrant")),
region = factor(region, levels = c("Northeast", "Midwest", "South", "West")),
urban_rural = factor(urban_rural, levels = c("Large central metro", "Large fringe metro", "Medium/small metro", "Nonmetropolitan")),
race_category = factor(race_category, levels = c("White", "Black", "AIAN", "AIAN + other", "Other races")),
housing_tenure = factor(housing_tenure, levels = c("Owned", "Rented", "Other arrangement")),
hispanic_ethnicity = factor(hispanic_ethnicity, levels = c(1, 2), labels = c("No", "Yes")),
hispanic_and_race = factor(hispanic_and_race, levels = c(1:7), labels = c("Hispanic",
"Non-Hispanic White only",
"Non-Hispanic Black only",
"Non-Hispanic Asian only",
"Non-Hispanic AIAN only",
"Non-Hispanic AIAN and any other group",
"Other single and multiple races")),
hispanic_details = factor(hispanic_details, levels = c(1, 2, 3), labels = c("Hispanic (Mexican)",
"Hispanic (all other group)", "Not Hispanic")),
marital_status = factor(marital_status, levels = c(1, 2, 3), labels = c("Married", "Single", "Divorced")),
parent_status = factor(parent_status, levels = c(1, 2, 3), labels = c("Parent", "Not a parent", "Unknown")),
sex = factor(sex, levels = c(1, 2, 9), labels = c("Male", "Female", "Other / Unknow")),
# factor - ordered
physical_health = factor(physical_health, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), ordered = TRUE),
anxiety_level = factor(anxiety_level, levels = c("A little", "Somewhere in between", "A lot"), ordered = TRUE),
depression_level = factor(depression_level, levels = c("A little", "Somewhere in between", "A lot"), ordered = TRUE),
education_level = factor(education_level, levels = c("Never attended", "Grades 1-11", "12th grade, no diploma", "GED", "High School Graduate", "Some college", "Associate degree: occupational", "Associate degree: academic", "Bachelor's degree", "Master's degree", "Doctoral"), ordered = TRUE),
max_education_level = factor(max_education_level, levels = c("Never attended", "Grades 1-11", "12th grade, no diploma", "GED", "High School Graduate", "Some college", "Associate degree: occupational", "Associate degree: academic", "Bachelor's", "Master's", "Doctoral"), ordered = TRUE),
years_in_household = factor(years_in_household, levels = c("Less than 1 year", "1-3 years", "4-10 years", "11-20 years", "More than 20 years"), ordered = TRUE),
life_satisfaction = factor(life_satisfaction, levels = c("Very dissatisfied", "Dissatisfied", "Satisfied", "Very satisfied"), ordered = TRUE),
discrimination_1 = factor(discrimination_1, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_2 = factor(discrimination_2, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_3 = factor(discrimination_3, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_4 = factor(discrimination_4, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_5 = factor(discrimination_5, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
age = as.numeric(age),
year = as.integer(year)
)
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var <- combined_data |>
ggplot(aes(x = reorder(data_group, -table(data_group)[data_group]), fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
# Save combined dataset ----
save(target_var, datagroup_var, file = here("data_combined/dist_barplots.rda"))
min_group_size <- combined_data |>
count(depression_ever) |>
pull(n) |>
min()
# Downsample the data to balance the target variable
balanced_data <- combined_data |>
group_by(depression_ever) |>
sample_n(size = min_group_size, replace = FALSE) |>
ungroup()
# Downsample each data_group to the target size and balance depression_ever
# Desired total size per data group
group_target_size <- 10000
# Function to balance each group
balanced_data <- combined_data |>
group_by(data_group, depression_ever) |>
group_modify(~ {
if (nrow(.x) < (group_target_size / 2)) {
# Upsample if not enough rows
.x |> slice_sample(n = group_target_size / 2, replace = TRUE)
} else {
# Downsample if too many rows
.x |> slice_sample(n = group_target_size / 2, replace = FALSE)
}
}) |>
ungroup()
# Check the final distribution
balanced_data |>
count(data_group, depression_ever) |>
print()
# Check the result to verify balance
write.csv(balanced_data, "data_combined/combined_nhis_data.csv", row.names = FALSE)
# data splitting
# load packages ----
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(janitor)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
combined_data <- read_csv(here("data_combined/combined_nhis_data.csv"))
# data split
data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
data_fold <- vfold_cv(data_train, v = 4, repeats = 3,
strata = depression_ever)
save(data_split, data_train, data_test, data_fold, file = here("attempt_1/results/data_split.rda"))
# Setup pre-processing/recipes - KITCHEN SINK
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_1/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# kitchen sink recipe
## for non tree (parametric) models
ks_recipe <- recipe(depression_ever ~ ., data = data_train) |>
step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
prep(ks_recipe) |>
bake(new_data = NULL)
## for  tree (non-parametric) models
ks_recipe_t <- recipe(depression_ever ~ ., data = data_train) |>
# Remove other unnecessary variables
step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
prep(ks_recipe_t) |>
bake(new_data = NULL)
save(ks_recipe, ks_recipe_t, file = "attempt_1/recipes/ks_recipes.rda")
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_1/results/data_split.rda"))
load(here("attempt_1/recipes/ks_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(ks_recipe)
# fit workflows/models ----
logistic_fit <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit, file = "attempt_1/results/a_logistic_fit.rda")
gc()
gc()
gc()
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_1/results/data_split.rda"))
load(here("attempt_1/recipes/ks_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(ks_recipe)
# fit workflows/models ----
logistic_fit <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit, file = "attempt_1/results/a_logistic_fit.rda")
gc()
# Setup pre-processing/recipes - M2 just groups
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_2/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# M2 recipe - just groups
## for non tree (parametric) models
m2_recipe <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details,
data = data_train) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
prep(m2_recipe) |>
bake(new_data = NULL)
## for  tree (non-parametric) models
m2_recipe_t <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details,
data = data_train) |>
# Remove other unnecessary variables
#step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
prep(m2_recipe_t) |>
bake(new_data = NULL)
save(m2_recipe, m2_recipe_t, file = here("attempt_2/recipes/m2_recipes.rda"))
gc()
gc()
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_2/results/data_split.rda"))
load(here("attempt_2/recipes/m2_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(m2_recipe)
# fit workflows/models ----
logistic_fit_b <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit_b, file = "attempt_2/results/b_logistic_fit.rda")
gc()
gc()
# data splitting
# load packages ----
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(janitor)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
combined_data <- read_csv(here("data_combined/combined_nhis_data.csv"))
# data split
data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
data_fold <- vfold_cv(data_train, v = 4, repeats = 3,
strata = depression_ever)
save(data_split, data_train, data_test, data_fold, file = here("attempt_3/results/data_split.rda"))
# Setup pre-processing/recipes - M3 just groups
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_3/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# M3 recipe - (m1 + m2) + tertiary factors
## for non tree (parametric) models
m3_recipe <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
prep(m3_recipe) |>
bake(new_data = NULL)
## for  tree (non-parametric) models
m3_recipe_t <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
# Remove other unnecessary variables
#step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
prep(m3_recipe_t) |>
bake(new_data = NULL)
save(m3_recipe, m3_recipe_t, file = here("attempt_3/recipes/m3_recipes.rda"))
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_3/results/data_split.rda"))
load(here("attempt_3/recipes/m3_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(m3_recipe)
# fit workflows/models ----
logistic_fit_c <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit_c, file = "attempt_3/results/c_logistic_fit.rda")
gc()
gc()
