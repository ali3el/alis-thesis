smoothness = tune(), # Hyperparameter for Laplace smoothing
Laplace = tune()     # Additional smoothing parameter
) |>
set_engine("klaR")      # Ensure 'klaR' package is installed
# Define workflow ----
nbayes_workflow <- workflow() |>
add_model(nbayes_model) |>
add_recipe(m1_recipe)
# Hyperparameter tuning values ----
nbayes_params <- extract_parameter_set_dials(nbayes_model)
# Create grid for tuning ----
nbayes_grid <- grid_regular(nbayes_params, levels = 3)
# Fit workflows/models ----
nbayes_fit_b <- tune_grid(
nbayes_workflow,
resamples = data_fold, # Assuming `data_fold` is your cross-validation folds
grid = nbayes_grid,
control = control_grid(save_workflow = TRUE)
)
# Load packages ----
library(tidyverse)
library(tidyverse)
library(tidymodels)
library(here)
library(xrf)
library(rules)
tidymodels_prefer()
# Set seed
set.seed(301)
# Load preprocessed data and recipe ----
load(here("attempt_2/results/data_split.rda"))
load(here("attempt_2/recipes/m1_recipes.rda"))
# Enable parallel processing ----
library(doMC)
registerDoMC(cores = parallel::detectCores(logical = TRUE))
# Set RuleFit model specification
rulefit_model <- rule_fit(
mode = "classification",
penalty = tune()
) |>
set_engine("xrf")
rulefit_workflow <- workflow() |>
add_model(rulefit_model) |>
add_recipe(m1_recipe_t)
rulefit_params <- extract_parameter_set_dials(rulefit_model)
rulefit_grid <- grid_regular(rulefit_params, levels = 3)
rulefit_fit_b <- tune_grid(
rulefit_workflow,
resamples = data_fold, # `data_fold` is my cross-validation folds
grid = rulefit_grid,
control = control_grid(save_workflow = TRUE)
)
save(rulefit_fit_b, file = here("attempt_2/results/b_rulefit_fit.rda"))
# naive bayes
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(discrim)
# Handle common conflicts
tidymodels_prefer()
# Set seed
set.seed(301)
# Load preprocessed data and recipe ----
load(here("attempt_2/results/data_split.rda"))
load(here("attempt_2/recipes/m1_recipes.rda"))
# Enable parallel processing ----
library(doMC)
registerDoMC(cores = parallel::detectCores(logical = TRUE))
# Model specifications ----
nbayes_model <-
naive_Bayes(
mode = "classification",
smoothness = tune(), # Hyperparameter for Laplace smoothing
Laplace = tune()     # Additional smoothing parameter
) |>
set_engine("klaR")      # Ensure 'klaR' package is installed
# Define workflow ----
nbayes_workflow <- workflow() |>
add_model(nbayes_model) |>
add_recipe(m1_recipe)
# Hyperparameter tuning values ----
nbayes_params <- extract_parameter_set_dials(nbayes_model)
# Create grid for tuning ----
nbayes_grid <- grid_regular(nbayes_params, levels = 3)
# Fit workflows/models ----
nbayes_fit_b <- tune_grid(
nbayes_workflow,
resamples = data_fold, # Assuming `data_fold` is your cross-validation folds
grid = nbayes_grid,
control = control_grid(save_workflow = TRUE)
)
# Save results (fitted/trained workflows) ----
save(nbayes_fit_b, file = "attempt_2/results/b_nbayes_fit.rda")
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_2/results/data_split.rda"))
load(here("attempt_2/recipes/m1_recipes.rda"))
load(here("attempt_2/results/b_logistic_fit.rda"))
load(here("attempt_2/results/b_dtree_fit.rda"))
load(here("attempt_2/results/b_nbayes_fit.rda"))
load(here("attempt_2/results/b_knn_fit.rda"))
load(here("attempt_2/results/b_rulefit_fit.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# results
logistic_result <- collect_metrics(logistic_fit_b) |>
mutate(model = "logistic")
logistic_result
dtree_result <- collect_metrics(dtree_fit_b) |>
mutate(model = "decision tree")
dtree_result
knn_result <- collect_metrics(knn_fit_b) |>
mutate(model = "KNN")
knn_result
nbayes_result <- collect_metrics(nbayes_fit_b) |>
mutate(model = "Naive Bayes")
nbayes_result
rulefit_result <- collect_metrics(rulefit_fit_b) |>
mutate(model = "RuleFit")
rulefit_result
log_b_acc <- logistic_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Logistic M1")
dtree_b_acc <- dtree_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Decision Tree M1")
knn_b_acc <- knn_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "KNN M1")
nbayes_b_acc <- nbayes_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Naive Bayes M1")
rulefit_b_acc <- rulefit_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "RuleFit M1")
table_b_accuracy <- bind_rows(log_b_acc, dtree_b_acc, knn_b_acc, nbayes_b_acc, rulefit_b_acc) |>
select(model, mean, std_err, n) |>
arrange(mean) |>
distinct()
table_b_accuracy
dtree_autoplot_b <- autoplot(dtree_fit_b, metric = "accuracy")
knn_autoplot_b <- autoplot(knn_fit_b, metric = "accuracy")
rulefit_autoplot_b <- autoplot(rulefit_fit_b, metric = "accuracy")
dtree_autoplot_b
knn_autoplot_b
rulefit_autoplot_b
save(table_b_accuracy, dtree_autoplot_b,
knn_autoplot_b, rulefit_autoplot_b,
file = here("attempt_2/results/metric_results_b.rda"))
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_1/results/metric_results.rda"))
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_1/results/metric_results_a.rda"))
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_1/results/metric_results_a.rda"))
load(here("attempt_2/results/metric_results_b.rda"))
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_1/results/metric_results_a.rda"))
View(table_b_accuracy)
View(table_a_accuracy)
#| label: tbl-metrics_ks
#| tbl-cap: "Accuracy of Kitchen Sink Recipe Based Models"
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
library(knitr)
load(here("attempt_1/results/metric_results_a.rda"))
table_a_accuracy |>
kable()
#| label: tbl-metrics_m1
#| tbl-cap: "Accuracy of Feature Engineered Recipe Based Models"
#| echo: FALSE
load(here("attempt_2/results/metric_results_b.rda"))
table_b_accuracy |>
kable()
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(readr)
library(dplyr)
# Handle common conflicts
tidymodels_prefer()
# Load datasets ----
data19 <- read.csv(here("data19/initial_cleaning_dataset.csv"))
data20 <- read.csv(here("data20/initial_cleaning_dataset.csv"))
data21 <- read.csv(here("data21/initial_cleaning_dataset.csv"))
data22 <- read.csv(here("data22/initial_cleaning_dataset.csv"))
data23 <- read.csv(here("data23/initial_cleaning_dataset.csv"))
# Rename columns using the rename dictionary
rename_dict <- list(
"EDUC_A" = "EDUCP_A",
"MAXEDUC_A" = "MAXEDUCP_A",
"EMPWRKLSWK_A" = "EMPWRKLSW1_A",
"LSATIS4R_A" = "LSATIS4_A"
)
rename_variables <- function(data, rename_dict) {
colnames(data) <- sapply(colnames(data), function(col) {
if (col %in% names(rename_dict)) {
rename_dict[[col]]
} else {
col
}
})
return(data)
}
# Rename columns across datasets
data19 <- rename_variables(data19, rename_dict)
data20 <- rename_variables(data20, rename_dict)
data21 <- rename_variables(data21, rename_dict)
data22 <- rename_variables(data22, rename_dict)
data23 <- rename_variables(data23, rename_dict)
# Create a unified list of all columns
all_vars <- unique(unlist(lapply(list(data19, data20, data21, data22, data23), colnames)))
# Function to add missing columns
add_missing_cols <- function(data, all_vars) {
missing_vars <- setdiff(all_vars, colnames(data))
for (var in missing_vars) {
data[[var]] <- NA  # Add missing columns as NA
}
return(data)
}
# Apply function to all datasets
data19 <- add_missing_cols(data19, all_vars)
data20 <- add_missing_cols(data20, all_vars)
data21 <- add_missing_cols(data21, all_vars)
data22 <- add_missing_cols(data22, all_vars)
data23 <- add_missing_cols(data23, all_vars)
# Print shared and unique columns across datasets
shared_columns <- Reduce(intersect, list(colnames(data19), colnames(data20), colnames(data21), colnames(data22), colnames(data23)))
unique_columns <- lapply(list(data19, data20, data21, data22, data23), function(data) setdiff(colnames(data), shared_columns))
cat("Shared Columns:\n", paste(shared_columns, collapse = ", "), "\n\n")
cat("Unique Columns:\n")
print(unique_columns)
# Create a unified list of all columns
all_vars <- unique(unlist(lapply(list(data19, data20, data21, data22, data23), colnames)))
# Add year column ----
data19$year <- 2019
data20$year <- 2020
data21$year <- 2021
data22$year <- 2022
data23$year <- 2023
# Combine datasets ----
combined_data <- bind_rows(data19, data20, data21, data22, data23)
combined_data <- combined_data |>
rename(
sex = SEX_A,
urban_rural = URBRRL,
physical_health = PHSTAT_A,
anxiety_freq = ANXFREQ_A,
anxiety_level = ANXLEVEL_A,
depression_freq = DEPFREQ_A,
depression_level = DEPLEVEL_A,
depression_ever = DEPEV_A,
anxiety_ever = ANXEV_A,
spouse_gender = SPOUSESEX_A,
sexual_orientation = ORIENT_A,
nativity_status = NATUSBORN_A,
data_group = group,
region = REGION,
education_level = EDUCP_A,
hypertension_ever = HYPEV_A,
race_category = RACEALLP_A,
years_in_household = HOUYRSLIV_A,
housing_tenure = HOUTENURE_A,
mental_health_therapy = MHTHRPY_A,
max_education_level = MAXEDUCP_A,
employment_last_week = EMPWRKLSW1_A,
not_covered = NOTCOV_A,
age = AGEP_A,
hispanic_ethnicity = HISP_A,
hispanic_and_race = HISPALLP_A,
hispanic_details = HISDETP_A,
marital_status = MARITAL_A,
parent_status = PARSTAT_A,
life_satisfaction = LSATIS4_A,
anxiety_screening = GAD2SCREEN_A,
depression_screening = PHQ2SCREEN_A,
discrimination_1 = DISCRIM1_A,
discrimination_2 = DISCRIM2_A,
discrimination_3 = DISCRIM3_A,
discrimination_4 = DISCRIM4_A,
discrimination_5 = DISCRIM5_A
) |>
mutate(
# binary variables
depression_freq = ifelse(is.na(depression_freq) & depression_ever == "No", 0, depression_freq),
anxiety_freq = ifelse(is.na(anxiety_freq) & depression_ever == "No", 0, anxiety_freq),
anxiety_freq = factor(anxiety_freq, levels = c(0, 1, 2, 3, 4, 5), ordered = TRUE),
depression_freq = factor(depression_freq, levels = c(0, 1, 2, 3, 4, 5), ordered = TRUE),
depression_ever = factor(depression_ever, levels = c(0, 1), labels = c("No", "Yes")),
anxiety_ever = factor(anxiety_ever, levels = c(0, 1), labels = c("No", "Yes")),
hypertension_ever = factor(hypertension_ever, levels = c("No", "Yes")),
mental_health_therapy = factor(mental_health_therapy, levels = c("No", "Yes")),
employment_last_week = factor(employment_last_week, levels = c("No", "Yes")),
not_covered = factor(not_covered, levels = c("Covered", "Not covered")),
anxiety_screening = factor(anxiety_screening, levels = c(0, 1), labels = c("No", "Yes")),
depression_screening = factor(depression_screening, levels = c(0, 1), labels = c("No", "Yes")),
# factor variables - no order necessary
spouse_gender = factor(spouse_gender, levels = c("Male", "Female")),
sexual_orientation = factor(sexual_orientation, levels = c(1, 2, 3, 4), labels = c("GayLesbian", "Straight", "Bisexual", "Other")),
nativity_status = factor(nativity_status, levels = c(1, 2), labels = c("Native-born", "Foreign-born")),
data_group = factor(data_group, levels = c("LGBTQ_NonMigrant", "LGBTQ_Migrant", "Straight_NonMigrant", "Straight_Migrant")),
region = factor(region, levels = c("Northeast", "Midwest", "South", "West")),
urban_rural = factor(urban_rural, levels = c("Large central metro", "Large fringe metro", "Medium/small metro", "Nonmetropolitan")),
race_category = factor(race_category, levels = c("White", "Black", "AIAN", "AIAN + other", "Other races")),
housing_tenure = factor(housing_tenure, levels = c("Owned", "Rented", "Other arrangement")),
hispanic_ethnicity = factor(hispanic_ethnicity, levels = c(1, 2), labels = c("No", "Yes")),
hispanic_and_race = factor(hispanic_and_race, levels = c(1:7), labels = c("Hispanic",
"Non-Hispanic White only",
"Non-Hispanic Black only",
"Non-Hispanic Asian only",
"Non-Hispanic AIAN only",
"Non-Hispanic AIAN and any other group",
"Other single and multiple races")),
hispanic_details = factor(hispanic_details, levels = c(1, 2, 3), labels = c("Hispanic (Mexican)",
"Hispanic (all other group)", "Not Hispanic")),
marital_status = factor(marital_status, levels = c(1, 2, 3), labels = c("Married", "Single", "Divorced")),
parent_status = factor(parent_status, levels = c(1, 2, 3), labels = c("Parent", "Not a parent", "Unknown")),
sex = factor(sex, levels = c(1, 2, 9), labels = c("Male", "Female", "Other / Unknow")),
# factor - ordered
physical_health = factor(physical_health, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), ordered = TRUE),
anxiety_level = factor(anxiety_level, levels = c("A little", "Somewhere in between", "A lot"), ordered = TRUE),
depression_level = factor(depression_level, levels = c("A little", "Somewhere in between", "A lot"), ordered = TRUE),
education_level = factor(education_level, levels = c("Never attended", "Grades 1-11", "12th grade, no diploma", "GED", "High School Graduate", "Some college", "Associate degree: occupational", "Associate degree: academic", "Bachelor's degree", "Master's degree", "Doctoral"), ordered = TRUE),
max_education_level = factor(max_education_level, levels = c("Never attended", "Grades 1-11", "12th grade, no diploma", "GED", "High School Graduate", "Some college", "Associate degree: occupational", "Associate degree: academic", "Bachelor's", "Master's", "Doctoral"), ordered = TRUE),
years_in_household = factor(years_in_household, levels = c("Less than 1 year", "1-3 years", "4-10 years", "11-20 years", "More than 20 years"), ordered = TRUE),
life_satisfaction = factor(life_satisfaction, levels = c("Very dissatisfied", "Dissatisfied", "Satisfied", "Very satisfied"), ordered = TRUE),
discrimination_1 = factor(discrimination_1, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_2 = factor(discrimination_2, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_3 = factor(discrimination_3, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_4 = factor(discrimination_4, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_5 = factor(discrimination_5, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
age = as.numeric(age),
year = as.integer(year)
)
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
target_var
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal()# +
target_var
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var <- combined_data |>
ggplot(aes(x = data_group, fill = data_group)) +
geom_bar() +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var
datagroup_var <- combined_data |>
ggplot(aes(x = data_group, fill = data_group)) +
geom_bar() +
facet_wrap(~ some_other_variable) +
labs(
title = "Distribution of Data Group by Another Variable",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var
datagroup_var <- combined_data |>
ggplot(aes(x = data_group, fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var
datagroup_var <- combined_data |>
ggplot(aes(x = reorder(data_group, -table(data_group)[data_group]), fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var
datagroup_var <- combined_data |>
ggplot(aes(x = reorder(data_group, -table(data_group)[data_group]), fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var <- combined_data |>
ggplot(aes(x = reorder(data_group, -table(data_group)[data_group]), fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
# Save combined dataset ----
save(target_var, datagroup_var, file = here("data_combined/dist_barplots.rda"))
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
library(knitr)
load(here("data_combined/dist_barplot.rda"))
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
library(knitr)
load(here("data_combined/dist_barplots.rda"))
load(here("attempt_1/results/metric_results_a.rda"))
load(here("attempt_2/results/metric_results_b.rda"))
#| label: fig-dist
#| fig-cap: "Distribution of Target Variable"
#| echo: false
target_var
#| label: fig-dist1
#| fig-cap: "Distribution of Focus Group"
#| echo: false
datagroup_var
