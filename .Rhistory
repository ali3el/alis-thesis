local_best_models |>
mutate(across(where(is.numeric), ~ round(.x, 3))) |>
rename(
`F1 Score` = f_meas,
`ROC AUC` = roc_auc,
`Std. Error (F1)` = std_err_f_meas,
`Attempt` = attempt,
`Platform` = platform,
`Feature Set` = recipe
) |> kable()
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(readr)
library(dplyr)
# Handle common conflicts
tidymodels_prefer()
# Load datasets ----
data19 <- read.csv(here("data19/initial_cleaning_dataset.csv"))
data20 <- read.csv(here("data20/initial_cleaning_dataset.csv"))
data21 <- read.csv(here("data21/initial_cleaning_dataset.csv"))
data22 <- read.csv(here("data22/initial_cleaning_dataset.csv"))
data23 <- read.csv(here("data23/initial_cleaning_dataset.csv"))
# Rename columns using the rename dictionary
rename_dict <- list(
"EDUC_A" = "EDUCP_A",
"MAXEDUC_A" = "MAXEDUCP_A",
"EMPWRKLSWK_A" = "EMPWRKLSW1_A",
"LSATIS4R_A" = "LSATIS4_A"
)
rename_variables <- function(data, rename_dict) {
colnames(data) <- sapply(colnames(data), function(col) {
if (col %in% names(rename_dict)) {
rename_dict[[col]]
} else {
col
}
})
return(data)
}
# Rename columns across datasets
data19 <- rename_variables(data19, rename_dict)
data20 <- rename_variables(data20, rename_dict)
data21 <- rename_variables(data21, rename_dict)
data22 <- rename_variables(data22, rename_dict)
data23 <- rename_variables(data23, rename_dict)
# Create a unified list of all columns
all_vars <- unique(unlist(lapply(list(data19, data20, data21, data22, data23), colnames)))
# Function to add missing columns
add_missing_cols <- function(data, all_vars) {
missing_vars <- setdiff(all_vars, colnames(data))
for (var in missing_vars) {
data[[var]] <- NA  # Add missing columns as NA
}
return(data)
}
# Apply function to all datasets
data19 <- add_missing_cols(data19, all_vars)
data20 <- add_missing_cols(data20, all_vars)
data21 <- add_missing_cols(data21, all_vars)
data22 <- add_missing_cols(data22, all_vars)
data23 <- add_missing_cols(data23, all_vars)
# Print shared and unique columns across datasets
shared_columns <- Reduce(intersect, list(colnames(data19), colnames(data20), colnames(data21), colnames(data22), colnames(data23)))
unique_columns <- lapply(list(data19, data20, data21, data22, data23), function(data) setdiff(colnames(data), shared_columns))
cat("Shared Columns:\n", paste(shared_columns, collapse = ", "), "\n\n")
cat("Unique Columns:\n")
print(unique_columns)
# Create a unified list of all columns
all_vars <- unique(unlist(lapply(list(data19, data20, data21, data22, data23), colnames)))
# Add year column ----
data19$year <- 2019
data20$year <- 2020
data21$year <- 2021
data22$year <- 2022
data23$year <- 2023
# Combine datasets ----
combined_data <- bind_rows(data19, data20, data21, data22, data23)
combined_data <- combined_data |>
rename(
sex = SEX_A,
urban_rural = URBRRL,
physical_health = PHSTAT_A,
anxiety_freq = ANXFREQ_A,
anxiety_level = ANXLEVEL_A,
depression_freq = DEPFREQ_A,
depression_level = DEPLEVEL_A,
depression_ever = DEPEV_A,
anxiety_ever = ANXEV_A,
spouse_gender = SPOUSESEX_A,
sexual_orientation = ORIENT_A,
nativity_status = NATUSBORN_A,
data_group = group,
region = REGION,
education_level = EDUCP_A,
hypertension_ever = HYPEV_A,
race_category = RACEALLP_A,
years_in_household = HOUYRSLIV_A,
housing_tenure = HOUTENURE_A,
mental_health_therapy = MHTHRPY_A,
max_education_level = MAXEDUCP_A,
employment_last_week = EMPWRKLSW1_A,
not_covered = NOTCOV_A,
age = AGEP_A,
hispanic_ethnicity = HISP_A,
hispanic_and_race = HISPALLP_A,
hispanic_details = HISDETP_A,
marital_status = MARITAL_A,
parent_status = PARSTAT_A,
life_satisfaction = LSATIS4_A,
anxiety_screening = GAD2SCREEN_A,
depression_screening = PHQ2SCREEN_A,
discrimination_1 = DISCRIM1_A,
discrimination_2 = DISCRIM2_A,
discrimination_3 = DISCRIM3_A,
discrimination_4 = DISCRIM4_A,
discrimination_5 = DISCRIM5_A
) |>
mutate(
# binary variables
depression_freq = ifelse(is.na(depression_freq) & depression_ever == "No", 0, depression_freq),
anxiety_freq = ifelse(is.na(anxiety_freq) & depression_ever == "No", 0, anxiety_freq),
anxiety_freq = factor(anxiety_freq, levels = c(0, 1, 2, 3, 4, 5), ordered = TRUE),
depression_freq = factor(depression_freq, levels = c(0, 1, 2, 3, 4, 5), ordered = TRUE),
depression_ever = factor(depression_ever, levels = c(0, 1), labels = c("No", "Yes")),
anxiety_ever = factor(anxiety_ever, levels = c(0, 1), labels = c("No", "Yes")),
hypertension_ever = factor(hypertension_ever, levels = c("No", "Yes")),
mental_health_therapy = factor(mental_health_therapy, levels = c("No", "Yes")),
employment_last_week = factor(employment_last_week, levels = c("No", "Yes")),
not_covered = factor(not_covered, levels = c("Covered", "Not covered")),
anxiety_screening = factor(anxiety_screening, levels = c(0, 1), labels = c("No", "Yes")),
depression_screening = factor(depression_screening, levels = c(0, 1), labels = c("No", "Yes")),
# factor variables - no order necessary
spouse_gender = factor(spouse_gender, levels = c("Male", "Female")),
sexual_orientation = factor(sexual_orientation, levels = c(1, 2, 3, 4), labels = c("GayLesbian", "Straight", "Bisexual", "Other")),
nativity_status = factor(nativity_status, levels = c(1, 2), labels = c("Native-born", "Foreign-born")),
data_group = factor(data_group, levels = c("LGBTQ_NonMigrant", "LGBTQ_Migrant", "Straight_NonMigrant", "Straight_Migrant")),
region = factor(region, levels = c("Northeast", "Midwest", "South", "West")),
urban_rural = factor(urban_rural, levels = c("Large central metro", "Large fringe metro", "Medium/small metro", "Nonmetropolitan")),
race_category = factor(race_category, levels = c("White", "Black", "AIAN", "AIAN + other", "Other races")),
housing_tenure = factor(housing_tenure, levels = c("Owned", "Rented", "Other arrangement")),
hispanic_ethnicity = factor(hispanic_ethnicity, levels = c(1, 2), labels = c("No", "Yes")),
hispanic_and_race = factor(hispanic_and_race, levels = c(1:7), labels = c("Hispanic",
"Non-Hispanic White only",
"Non-Hispanic Black only",
"Non-Hispanic Asian only",
"Non-Hispanic AIAN only",
"Non-Hispanic AIAN and any other group",
"Other single and multiple races")),
hispanic_details = factor(hispanic_details, levels = c(1, 2, 3), labels = c("Hispanic (Mexican)",
"Hispanic (all other group)", "Not Hispanic")),
marital_status = factor(marital_status, levels = c(1, 2, 3), labels = c("Married", "Single", "Divorced")),
parent_status = factor(parent_status, levels = c(1, 2, 3), labels = c("Parent", "Not a parent", "Unknown")),
sex = factor(sex, levels = c(1, 2, 9), labels = c("Male", "Female", "Other / Unknow")),
# factor - ordered
physical_health = factor(physical_health, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), ordered = TRUE),
anxiety_level = factor(anxiety_level, levels = c("A little", "Somewhere in between", "A lot"), ordered = TRUE),
depression_level = factor(depression_level, levels = c("A little", "Somewhere in between", "A lot"), ordered = TRUE),
education_level = factor(education_level, levels = c("Never attended", "Grades 1-11", "12th grade, no diploma", "GED", "High School Graduate", "Some college", "Associate degree: occupational", "Associate degree: academic", "Bachelor's degree", "Master's degree", "Doctoral"), ordered = TRUE),
max_education_level = factor(max_education_level, levels = c("Never attended", "Grades 1-11", "12th grade, no diploma", "GED", "High School Graduate", "Some college", "Associate degree: occupational", "Associate degree: academic", "Bachelor's", "Master's", "Doctoral"), ordered = TRUE),
years_in_household = factor(years_in_household, levels = c("Less than 1 year", "1-3 years", "4-10 years", "11-20 years", "More than 20 years"), ordered = TRUE),
life_satisfaction = factor(life_satisfaction, levels = c("Very dissatisfied", "Dissatisfied", "Satisfied", "Very satisfied"), ordered = TRUE),
discrimination_1 = factor(discrimination_1, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_2 = factor(discrimination_2, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_3 = factor(discrimination_3, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_4 = factor(discrimination_4, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_5 = factor(discrimination_5, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
age = as.numeric(age),
year = as.integer(year)
)
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var <- combined_data |>
ggplot(aes(x = reorder(data_group, -table(data_group)[data_group]), fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
# Save combined dataset ----
save(target_var, datagroup_var, file = here("data_combined/dist_barplots.rda"))
min_group_size <- combined_data |>
count(depression_ever) |>
pull(n) |>
min()
# Downsample the data to balance the target variable
balanced_data <- combined_data |>
group_by(depression_ever) |>
sample_n(size = min_group_size, replace = FALSE) |>
ungroup()
# Downsample each data_group to the target size and balance depression_ever
# Desired total size per data group
group_target_size <- 10000
# Function to balance each group
balanced_data <- combined_data |>
group_by(data_group, depression_ever) |>
group_modify(~ {
if (nrow(.x) < (group_target_size / 2)) {
# Upsample if not enough rows
.x |> slice_sample(n = group_target_size / 2, replace = TRUE)
} else {
# Downsample if too many rows
.x |> slice_sample(n = group_target_size / 2, replace = FALSE)
}
}) |>
ungroup()
# Check the final distribution
balanced_data |>
count(data_group, depression_ever) |>
print()
# Check the result to verify balance
write.csv(balanced_data, "data_combined/combined_nhis_data.csv", row.names = FALSE)
unique(balanced_data$depression_freq)
no_dep <- balanced_data |>
filter(depression_ever = "No")
no_dep <- balanced_data |>
filter(depression_ever == "No")
summary(no_dep$depression_freq)
#| label: fig-dist1
#| fig-cap: "Distribution of Focus Group"
#| echo: false
#| fig-pos="H"
datagroup_var
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
library(knitr)
library(kableExtra)
load(here("data_combined/dist_barplots.rda"))
#| label: fig-dist1
#| fig-cap: "Distribution of Focus Group"
#| echo: false
#| fig-pos: "H"
datagroup_var
#| label: fig-f1
#| fig-cap: "F1 Scores by Model and Feature Set (Grouped by Platform)"
#| echo: false
load(here("visualizations/plots/combined_model_comparison_plots.rda"))
f1_plot
#| label: fig-f1
#| fig-cap: "F1 Scores by Model and Feature Set (Grouped by Platform)"
#| echo: false
load(here("visualizations/plots/combined_model_comparison_plots.rda"))
f1_plot + xlab("Feature Set")
#| label: tbl-local
#| tbl-cap: "Accuracy by Model and Feature Set (Grouped by Platform) - Local"
#| echo: false
#| tbl-pos: "H"
load(here("master_comparison/local_model_results.rda"))
local_best_models |>
mutate(across(where(is.numeric), ~ round(.x, 3))) |>
rename(
`F1 Score` = f_meas,
`ROC AUC` = roc_auc,
`Std. Error (F1)` = std_err_f_meas,
`Attempt` = attempt,
`Platform` = platform,
`Feature Set` = recipe
) |> kable()
#| label: tbl-local
#| tbl-cap: "Accuracy by Model and Feature Set (Grouped by Platform) - Local"
#| echo: false
#| tbl-pos: "H"
load(here("master_comparison/local_model_results.rda"))
local_best_models |>
mutate(across(where(is.numeric), ~ round(.x, 3))) |>
rename(
`F1 Score` = f_meas,
`ROC AUC` = roc_auc,
`Std. Error (F1)` = std_err_f_meas,
`Attempt` = attempt,
`Platform` = platform,
`Feature Set` = recipe
) |> kable(booktabs = TRUE, longtable = TRUE, linesep = "", align = "c") |>
kable_styling(latex_options = c("hold_position", "scale_down"))
#| label: tbl-local
#| tbl-cap: "Accuracy by Model and Feature Set (Grouped by Platform) - Local"
#| echo: false
#| tbl-pos: "H"
load(here("master_comparison/local_model_results.rda"))
local_best_models |>
mutate(across(where(is.numeric), ~ round(.x, 3))) |>
rename(
`F1 Score` = f_meas,
`ROC AUC` = roc_auc,
`Std. Error (F1)` = std_err_f_meas,
`Attempt` = attempt,
`Platform` = platform,
`Feature Set` = recipe
) |> kable(booktabs = TRUE, longtable = TRUE, escape = FALSE) |>
kable_styling(
latex_options = c("hold_position", "scale_down"),
font_size = 9
#| label: tbl-local
#| tbl-cap: "Accuracy by Model and Feature Set (Grouped by Platform) - Local"
#| echo: false
#| tbl-pos: "H"
load(here("master_comparison/local_model_results.rda"))
local_best_models |>
mutate(across(where(is.numeric), ~ round(.x, 3))) |>
rename(
`F1 Score` = f_meas,
`ROC AUC` = roc_auc,
`Std. Error (F1)` = std_err_f_meas,
`Attempt` = attempt,
`Platform` = platform,
`Feature Set` = recipe
) |> kable(booktabs = TRUE, longtable = TRUE, escape = FALSE) |> kable_styling(
latex_options = c("hold_position", "scale_down"),
font_size = 9
#| label: tbl-local
#| tbl-cap: "Accuracy by Model and Feature Set (Grouped by Platform) - Local"
#| echo: false
#| tbl-pos: "H"
load(here("master_comparison/local_model_results.rda"))
local_best_models |>
mutate(across(where(is.numeric), ~ round(.x, 3))) |>
rename(
`F1 Score` = f_meas,
`ROC AUC` = roc_auc,
`Std. Error (F1)` = std_err_f_meas,
`Attempt` = attempt,
`Platform` = platform,
`Feature Set` = recipe
) |>
kable(booktabs = TRUE, longtable = TRUE, escape = FALSE) |>
kable_styling(
latex_options = c("hold_position", "scale_down"),
font_size = 9)
#| label: tbl-local
#| tbl-cap: "Accuracy by Model and Feature Set (Grouped by Platform) - Local"
#| echo: false
#| tbl-pos: "H"
load(here("master_comparison/local_model_results.rda"))
local_best_models |>
mutate(across(where(is.numeric), ~ round(.x, 3))) |>
rename(
`F1 Score` = f_meas,
`ROC AUC` = roc_auc,
`Std. Error (F1)` = std_err_f_meas,
`Attempt` = attempt,
`Platform` = platform,
`Feature Set` = recipe
) |>
kable(booktabs = TRUE, longtable = TRUE, escape = FALSE) |>
kable_styling(
latex_options = c("hold_position"),
font_size = 9
)
library(tidyverse)
library(here)
# ---- STEP 1: Load attempt summary tables ----
load(here("attempt_1/results/attempt_1_summary_table.rda"))  # summary_final_attempt1
load(here("attempt_2/results/attempt_2_summary_table.rda"))
load(here("attempt_3/results/attempt_3_summary_table.rda"))
load(here("attempt_4/results/attempt_4_summary_table.rda"))
load(here("attempt_5/results/attempt_5_summary_table.rda"))
# ---- STEP 2: Define recipe labels for each attempt (customize these) ----
recipe_labels <- c(
"Kitchen Sink",
"M2",
"M3",
"M1",
"M4"
)
# ---- STEP 3: Add metad
# ---- STEP 3: Add metadata to each attempt ----
summary_final_attempt1 <- summary_final_attempt1 |>
mutate(attempt = 1, platform = "Local", recipe = recipe_labels[1])
summary_final_attempt2 <- summary_final_attempt2 |>
mutate(attempt = 2, platform = "Local", recipe = recipe_labels[2])
summary_final_attempt3 <- summary_final_attempt3 |>
mutate(attempt = 3, platform = "Local", recipe = recipe_labels[3])
summary_final_attempt4 <- summary_final_attempt4 |>
mutate(attempt = 4, platform = "Local", recipe = recipe_labels[4])
summary_final_attempt5 <- summary_final_attempt5 |>
mutate(attempt = 5, platform = "Local", recipe = recipe_labels[5])
# ---- STEP 4: Combine all into one table ----
local_summary_all <- bind_rows(
summary_final_attempt1,
summary_final_attempt2,
summary_final_attempt3,
summary_final_attempt4,
summary_final_attempt5
)
# ---- STEP 5: Create best model per attempt table (based on F1-score) ----
local_best_models <- local_summary_all |>
group_by(attempt) |>
filter(f_meas == max(f_meas, na.rm = TRUE)) |>
ungroup() |>
arrange(attempt)
# ---- STEP 5: Create best model per attempt table (based on F1-score) ----
local_best_models <- local_summary_all |>
group_by(attempt) |>
filter(f_meas == max(f_meas, na.rm = TRUE)) |>
ungroup() |>
arrange(desc(f_meas))
local_best_models
# ---- STEP 5: Create best model per attempt table (based on F1-score) ----
local_best_models <- local_summary_all |>
group_by(attempt) |>
filter(f_meas == max(f_meas, na.rm = TRUE)) |>
ungroup() |>
arrange(desc(f_meas), desc(roc_auc)) |>
slice_head(n = 5)
local_best_models
library(tidyverse)
library(here)
# ---- STEP 1: Load attempt summary tables ----
load(here("attempt_1/results/attempt_1_summary_table.rda"))  # summary_final_attempt1
load(here("attempt_2/results/attempt_2_summary_table.rda"))
load(here("attempt_3/results/attempt_3_summary_table.rda"))
load(here("attempt_4/results/attempt_4_summary_table.rda"))
load(here("attempt_5/results/attempt_5_summary_table.rda"))
# ---- STEP 2: Define recipe labels for each attempt (customize these) ----
recipe_labels <- c(
"Kitchen Sink",
"M2",
"M3",
"M1",
"M4"
)
# ---- STEP 3: Add metadata to each attempt ----
summary_final_attempt1 <- summary_final_attempt1 |>
mutate(attempt = 1, platform = "Local", recipe = recipe_labels[1])
summary_final_attempt2 <- summary_final_attempt2 |>
mutate(attempt = 2, platform = "Local", recipe = recipe_labels[2])
summary_final_attempt3 <- summary_final_attempt3 |>
mutate(attempt = 3, platform = "Local", recipe = recipe_labels[3])
summary_final_attempt4 <- summary_final_attempt4 |>
mutate(attempt = 4, platform = "Local", recipe = recipe_labels[4])
summary_final_attempt5 <- summary_final_attempt5 |>
mutate(attempt = 5, platform = "Local", recipe = recipe_labels[5])
# ---- STEP 4: Combine all into one table ----
local_summary_all <- bind_rows(
summary_final_attempt1,
summary_final_attempt2,
summary_final_attempt3,
summary_final_attempt4,
summary_final_attempt5
)
# ---- STEP 5: Create best model per attempt table (based on F1-score) ----
local_best_models <- local_summary_all |>
group_by(attempt) |>
filter(f_meas == max(f_meas, na.rm = TRUE)) |>
ungroup() |>
arrange(desc(f_meas), desc(roc_auc)) |>
slice_head(n = 5)
# ---- STEP 6: (Optional) Save cleaned full dataset ----
save(local_summary_all, local_best_models, file = here("master_comparison/local_model_results.rda"))
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
library(knitr)
library(kableExtra)
load(here("data_combined/dist_barplots.rda"))
#| label: fig-dist1
#| fig-cap: "Distribution of Focus Group"
#| echo: false
#| fig-pos: "H"
datagroup_var
#| label: fig-dist2
#| fig-cap: "Distribution of Target Variable"
#| echo: false
#| fig-pos: "H"
target_var
#| label: fig-f1
#| fig-cap: "F1 Scores by Model and Feature Set (Grouped by Platform)"
#| echo: false
load(here("visualizations/plots/combined_model_comparison_plots.rda"))
f1_plot + xlab("Feature Set")
#| label: fig-acc
#| fig-cap: "Accuracy by Model and Feature Set (Grouped by Platform)"
#| echo: false
#| fig-pos: "H"
accuracy_plot + xlab("Feature Set")
#| label: fig-roc
#| fig-cap: "ROC AUC by Model and Feature Set (Grouped by Platform)"
#| echo: false
#| fig-pos: "H"
roc_plot + xlab("Feature Set")
#| label: fig-local-ks
#| fig-cap: "Local explanation for a single observation (Kitchen Sink model – Decision Tree)"
#| echo: false
#| fig-pos: "H"
#| fig-width: 8
#| fig-height: 5
load(here("model_explainability/results/local_explanation_ks.rda"))
local_plot_ks +  ggtitle("Local Explanation – Kitchen Sink Model",
subtitle = "Quest Pipeline – Decision Tree")
#| label: fig-local-m3
#| fig-cap: "Local explanation for a single observation (M3 model – Decision Tree)"
#| echo: false
#| fig-pos: "H"
load(here("model_explainability/results/local_explanation_m3.rda"))
local_plot_m3 +  ggtitle("Local Explanation",
subtitle = "Quest Pipeline – Decision Tree")
