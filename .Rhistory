rulefit_params <- extract_parameter_set_dials(rulefit_model)
rulefit_grid <- grid_regular(rulefit_params, levels = 5)
rulefit_fit_d <- tune_grid(
rulefit_workflow,
resamples = data_fold, # `data_fold` is my cross-validation folds
grid = rulefit_grid,
control = control_grid(save_workflow = TRUE)
)
save(rulefit_fit_d, file = here("attempt_4/results/d_rulefit_fit.rda"))
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_4/results/data_split.rda"))
load(here("attempt_4/recipes/m1_recipes.rda"))
load(here("attempt_4/results/c_logistic_fit.rda"))
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_4/results/data_split.rda"))
load(here("attempt_4/recipes/m1_recipes.rda"))
load(here("attempt_4/results/d_logistic_fit.rda"))
load(here("attempt_4/results/d_dtree_fit.rda"))
load(here("attempt_4/results/d_nbayes_fit.rda"))
load(here("attempt_4/results/d_knn_fit.rda"))
load(here("attempt_4/results/d_rulefit_fit.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
logistic_result <- collect_metrics(logistic_fit_d) |>
mutate(model = "logistic")
logistic_result
dtree_result <- collect_metrics(dtree_fit_d) |>
mutate(model = "decision tree")
dtree_result
knn_result <- collect_metrics(knn_fit_d) |>
mutate(model = "KNN")
knn_result
nbayes_result <- collect_metrics(nbayes_fit_d) |>
mutate(model = "Naive Bayes")
nbayes_result
rulefit_result <- collect_metrics(rulefit_fit_d) |>
mutate(model = "RuleFit")
rulefit_result
log_d_acc <- logistic_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Logistic M1")
dtree_d_acc <- dtree_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Decision Tree M1")
knn_d_acc <- knn_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "KNN M1")
nbayes_d_acc <- nbayes_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Naive Bayes M1")
rulefit_d_acc <- rulefit_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "RuleFit M1")
table_d_accuracy <- bind_rows(log_d_acc, dtree_d_acc, knn_d_acc, nbayes_d_acc, rulefit_d_acc) |>
select(model, mean, std_err, n) |>
arrange(mean) |>
distinct()
table_d_accuracy
dtree_autoplot_d <- autoplot(dtree_fit_d, metric = "accuracy")
knn_autoplot_d <- autoplot(knn_fit_d, metric = "accuracy")
rulefit_autoplot_d <- autoplot(rulefit_fit_d, metric = "accuracy")
rulefit_autoplot_d
knn_autoplot_d
dtree_autoplot_d
save(table_d_accuracy, dtree_autoplot_d,
knn_autoplot_d, rulefit_autoplot_d,
file = here("attempt_4/results/metric_results_d.rda"))
# data splitting
# load packages ----
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(janitor)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
combined_data <- read_csv(here("data_combined/combined_nhis_data.csv"))
# data split
data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
data_fold <- vfold_cv(data_train, v = 4, repeats = 3,
strata = depression_ever)
save(data_split, data_train, data_test, data_fold, file = here("attempt_5/results/data_split.rda"))
load(here("attempt_5/results/data_split.rda"))
load(here("attempt_5/results/data_split.rda"))
View(data_train)
# Setup pre-processing/recipes - M3 just groups
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_5/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# M4 recipe
## for non tree (parametric) models
m4_recipe <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status + marital_status + employment_last_week + physical_health +
mental_health_therapy + housing_tenure,
data = data_train) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
prep(m4_recipe) |>
bake(new_data = NULL)
## for  tree (non-parametric) models
m4_recipe_t <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status + marital_status + employment_last_week + physical_health +
mental_health_therapy + housing_tenure,
data = data_train) |>
# Remove other unnecessary variables
#step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
prep(m4_recipe_t) |>
bake(new_data = NULL)
save(m4_recipe, m4_recipe_t, file = here("attempt_5/recipes/m4_recipes.rda"))
# decision tree
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# Handle common conflicts
tidymodels_prefer()
# Set seed
set.seed(301)
# Load preprocessed data and recipe ----
load(here("attempt_5/results/data_split.rda"))
load(here("attempt_5/recipes/m4_recipes.rda"))
# Enable parallel processing ----
library(doMC)
registerDoMC(cores = parallel::detectCores(logical = TRUE))
# Model specifications ----
dtree_model <-
decision_tree(
mode = "classification",
cost_eomplexity = tune(),   # Controls pruning
tree_depth = tune(),        # Max depth of tree
min_n = tune()              # Minimum samples required for a split
) |>
set_engine("rpart")           # Use the rpart engine
# Model specifications ----
dtree_model <-
decision_tree(
mode = "classification",
cost_eomplexity = tune(),   # Controls pruning
tree_depth = tune(),        # Max depth of tree
min_n = tune()              # Minimum samples required for a split
) |>
set_engine("rpart")           # Use the rpart engine
# Model specifications ----
dtree_model <-
decision_tree(
mode = "classification",
cost_complexity = tune(),   # Controls pruning
tree_depth = tune(),        # Max depth of tree
min_n = tune()              # Minimum samples required for a split
) |>
set_engine("rpart")           # Use the rpart engine
# Define workflow ----
dtree_workflow <- workflow() |>
add_model(dtree_model) |>
add_recipe(m4_recipe_t)
dtree_params <- extract_parameter_set_dials(dtree_model)
# decision tree
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# Handle common conflicts
tidymodels_prefer()
# Set seed
set.seed(301)
# Load preprocessed data and recipe ----
load(here("attempt_5/results/data_split.rda"))
load(here("attempt_5/recipes/m4_recipes.rda"))
# Enable parallel processing ----
library(doMC)
registerDoMC(cores = parallel::detectCores(logical = TRUE))
# Model specifications ----
dtree_model <-
decision_tree(
mode = "classification",
cost_complexity = tune(),   # Controls pruning
tree_depth = tune(),        # Max depth of tree
min_n = tune()              # Minimum samples required for a split
) |>
set_engine("rpart")           # Use the rpart engine
# Define workflow ----
dtree_workflow <- workflow() |>
add_model(dtree_model) |>
add_recipe(m4_recipe_t)
dtree_params <- extract_parameter_set_dials(dtree_model)
dtree_grid <- grid_regular(dtree_params, levels = 5)
dtree_fit_e <- tune_grid(
dtree_workflow,
resamples = data_fold,        # Assuming `data_fold` is your cross-validation folds
grid = dtree_grid,
control = control_grid(save_workflow = TRUE)
)
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_5/results/data_split.rda"))
load(here("attempt_5/recipes/m4_recipes.rda"))
load(here("attempt_5/results/e_logistic_fit.rda"))
load(here("attempt_5/results/e_dtree_fit.rda"))
load(here("attempt_5/results/e_nbayes_fit.rda"))
load(here("attempt_5/results/e_knn_fit.rda"))
load(here("attempt_5/results/e_rulefit_fit.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# results
logistic_result <- collect_metrics(logistic_fit_e) |>
mutate(model = "logistic")
logistic_result
dtree_result <- collect_metrics(dtree_fit_e) |>
mutate(model = "decision tree")
dtree_result
knn_result <- collect_metrics(knn_fit_e) |>
mutate(model = "KNN")
knn_result
nbayes_result <- collect_metrics(nbayes_fit_e) |>
mutate(model = "Naive Bayes")
nbayes_result
rulefit_result <- collect_metrics(rulefit_fit_e) |>
mutate(model = "RuleFit")
rulefit_result
log_e_acc <- logistic_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Logistic M4")
dtree_e_acc <- dtree_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Decision Tree M4")
knn_e_acc <- knn_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "KNN M4")
nbayes_e_acc <- nbayes_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Naive Bayes M4")
rulefit_e_acc <- rulefit_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "RuleFit M4")
table_e_accuracy <- bind_rows(log_e_acc, dtree_e_acc, knn_e_acc, nbayes_e_acc, rulefit_e_acc) |>
select(model, mean, std_err, n) |>
arrange(mean) |>
distinct()
table_e_accuracy
dtree_autoplot_e <- autoplot(dtree_fit_e, metric = "accuracy")
knn_autoplot_e <- autoplot(knn_fit_e, metric = "accuracy")
rulefit_autoplot_e <- autoplot(rulefit_fit_e, metric = "accuracy")
# nbayes_autoplot_a <- autoplot(nbayes_fit, metric = "accuracy")
save(table_e_accuracy, dtree_autoplot_e,
knn_autoplot_e, rulefit_autoplot_e,
file = here("attempt_5/results/metric_results_e.rda"))
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_5/results/data_split.rda"))
load(here("attempt_5/recipes/m4_recipes.rda"))
load(here("attempt_5/results/e_logistic_fit.rda"))
load(here("attempt_5/results/e_dtree_fit.rda"))
load(here("attempt_5/results/e_nbayes_fit.rda"))
load(here("attempt_5/results/e_knn_fit.rda"))
load(here("attempt_5/results/e_rulefit_fit.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# results
logistic_result <- collect_metrics(logistic_fit_e) |>
mutate(model = "logistic")
logistic_result
dtree_result <- collect_metrics(dtree_fit_e) |>
mutate(model = "decision tree")
dtree_result
knn_result <- collect_metrics(knn_fit_e) |>
mutate(model = "KNN")
knn_result
nbayes_result <- collect_metrics(nbayes_fit_e) |>
mutate(model = "Naive Bayes")
nbayes_result
rulefit_result <- collect_metrics(rulefit_fit_e) |>
mutate(model = "RuleFit")
rulefit_result
log_e_acc <- logistic_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Logistic M4")
dtree_e_acc <- dtree_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Decision Tree M4")
knn_e_acc <- knn_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "KNN M4")
nbayes_e_acc <- nbayes_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Naive Bayes M4")
rulefit_e_acc <- rulefit_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "RuleFit M4")
table_e_accuracy <- bind_rows(log_e_acc, dtree_e_acc, knn_e_acc, nbayes_e_acc, rulefit_e_acc) |>
select(model, mean, std_err, n) |>
arrange(mean) |>
distinct()
table_e_accuracy
dtree_autoplot_e <- autoplot(dtree_fit_e, metric = "accuracy")
knn_autoplot_e <- autoplot(knn_fit_e, metric = "accuracy")
rulefit_autoplot_e <- autoplot(rulefit_fit_e, metric = "accuracy")
# nbayes_autoplot_a <- autoplot(nbayes_fit, metric = "accuracy")
save(table_e_accuracy, dtree_autoplot_e,
knn_autoplot_e, rulefit_autoplot_e,
file = here("attempt_5/results/metric_results_e.rda"))
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_4/results/data_split.rda"))
load(here("attempt_4/recipes/m1_recipes.rda"))
load(here("attempt_4/results/d_logistic_fit.rda"))
load(here("attempt_4/results/d_dtree_fit.rda"))
load(here("attempt_4/results/d_nbayes_fit.rda"))
load(here("attempt_4/results/d_knn_fit.rda"))
load(here("attempt_4/results/d_rulefit_fit.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# results
logistic_result <- collect_metrics(logistic_fit_d) |>
mutate(model = "logistic")
logistic_result
dtree_result <- collect_metrics(dtree_fit_d) |>
mutate(model = "decision tree")
dtree_result
knn_result <- collect_metrics(knn_fit_d) |>
mutate(model = "KNN")
knn_result
nbayes_result <- collect_metrics(nbayes_fit_d) |>
mutate(model = "Naive Bayes")
nbayes_result
rulefit_result <- collect_metrics(rulefit_fit_d) |>
mutate(model = "RuleFit")
rulefit_result
log_d_acc <- logistic_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Logistic M1")
dtree_d_acc <- dtree_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Decision Tree M1")
knn_d_acc <- knn_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "KNN M1")
nbayes_d_acc <- nbayes_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Naive Bayes M1")
rulefit_d_acc <- rulefit_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "RuleFit M1")
table_d_accuracy <- bind_rows(log_d_acc, dtree_d_acc, knn_d_acc, nbayes_d_acc, rulefit_d_acc) |>
select(model, mean, std_err, n) |>
arrange(mean) |>
distinct()
table_d_accuracy
dtree_autoplot_d <- autoplot(dtree_fit_d, metric = "accuracy")
knn_autoplot_d <- autoplot(knn_fit_d, metric = "accuracy")
rulefit_autoplot_d <- autoplot(rulefit_fit_d, metric = "accuracy")
# nbayes_autoplot_a <- autoplot(nbayes_fit, metric = "accuracy")
save(table_d_accuracy, dtree_autoplot_d,
knn_autoplot_d, rulefit_autoplot_d,
file = here("attempt_4/results/metric_results_d.rda"))
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_1/results/metric_results_a.rda"))
load(here("attempt_2/results/metric_results_b.rda"))
load(here("attempt_3/results/metric_results_c.rda"))
load(here("attempt_4/results/metric_results_d.rda"))
load(here("attempt_5/results/metric_results_e.rda"))
combined_table <-
bind_rows(table_a_accuracy, table_b_accuracy, table_c_accuracy,
table_d_accuracy, table_e_accuracy)
combined_table
combined_table <-
bind_rows(table_a_accuracy, table_b_accuracy, table_c_accuracy,
table_d_accuracy, table_e_accuracy) |>
knitr::kable()
combined_table
knitr::kable()
combined_table <-
bind_rows(table_a_accuracy, table_b_accuracy, table_c_accuracy,
table_d_accuracy, table_e_accuracy) |>
arrange(desc(mean)) |>
knitr::kable()
source("~/Desktop/Thesis/Untitled.R", echo=TRUE)
combined_table <-
bind_rows(table_a_accuracy, table_b_accuracy, table_c_accuracy,
table_d_accuracy, table_e_accuracy) |>
arrange(desc(mean)) |>
knitr::kable()
combined_table
