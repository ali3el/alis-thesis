urban_rural = factor(urban_rural, levels = c("Large central metro", "Large fringe metro", "Medium/small metro", "Nonmetropolitan")),
race_category = factor(race_category, levels = c("White", "Black", "AIAN", "AIAN + other", "Other races")),
housing_tenure = factor(housing_tenure, levels = c("Owned", "Rented", "Other arrangement")),
hispanic_ethnicity = factor(hispanic_ethnicity, levels = c(1, 2), labels = c("No", "Yes")),
hispanic_and_race = factor(hispanic_and_race, levels = c(1:7), labels = c("Hispanic",
"Non-Hispanic White only",
"Non-Hispanic Black only",
"Non-Hispanic Asian only",
"Non-Hispanic AIAN only",
"Non-Hispanic AIAN and any other group",
"Other single and multiple races")),
hispanic_details = factor(hispanic_details, levels = c(1, 2, 3), labels = c("Hispanic (Mexican)",
"Hispanic (all other group)", "Not Hispanic")),
marital_status = factor(marital_status, levels = c(1, 2, 3), labels = c("Married", "Single", "Divorced")),
parent_status = factor(parent_status, levels = c(1, 2, 3), labels = c("Parent", "Not a parent", "Unknown")),
sex = factor(sex, levels = c(1, 2, 9), labels = c("Male", "Female", "Other / Unknow")),
# factor - ordered
physical_health = factor(physical_health, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), ordered = TRUE),
anxiety_level = factor(anxiety_level, levels = c("A little", "Somewhere in between", "A lot"), ordered = TRUE),
depression_level = factor(depression_level, levels = c("A little", "Somewhere in between", "A lot"), ordered = TRUE),
education_level = factor(education_level, levels = c("Never attended", "Grades 1-11", "12th grade, no diploma", "GED", "High School Graduate", "Some college", "Associate degree: occupational", "Associate degree: academic", "Bachelor's degree", "Master's degree", "Doctoral"), ordered = TRUE),
max_education_level = factor(max_education_level, levels = c("Never attended", "Grades 1-11", "12th grade, no diploma", "GED", "High School Graduate", "Some college", "Associate degree: occupational", "Associate degree: academic", "Bachelor's", "Master's", "Doctoral"), ordered = TRUE),
years_in_household = factor(years_in_household, levels = c("Less than 1 year", "1-3 years", "4-10 years", "11-20 years", "More than 20 years"), ordered = TRUE),
life_satisfaction = factor(life_satisfaction, levels = c("Very dissatisfied", "Dissatisfied", "Satisfied", "Very satisfied"), ordered = TRUE),
discrimination_1 = factor(discrimination_1, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_2 = factor(discrimination_2, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_3 = factor(discrimination_3, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_4 = factor(discrimination_4, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
discrimination_5 = factor(discrimination_5, levels = c("Never", "Less than once a year", "A few times a year", "A few times a month", "At least once a week"), ordered = TRUE),
age = as.numeric(age),
year = as.integer(year)
)
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
target_var
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal()# +
target_var
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var <- combined_data |>
ggplot(aes(x = data_group, fill = data_group)) +
geom_bar() +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var
datagroup_var <- combined_data |>
ggplot(aes(x = data_group, fill = data_group)) +
geom_bar() +
facet_wrap(~ some_other_variable) +
labs(
title = "Distribution of Data Group by Another Variable",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var
datagroup_var <- combined_data |>
ggplot(aes(x = data_group, fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var
datagroup_var <- combined_data |>
ggplot(aes(x = reorder(data_group, -table(data_group)[data_group]), fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var
datagroup_var <- combined_data |>
ggplot(aes(x = reorder(data_group, -table(data_group)[data_group]), fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
target_var <- combined_data |>
ggplot(aes(x = depression_ever, fill = depression_ever)) +
geom_bar() +
labs(
title = "Distribution of Target Variable - Depression Ever",
x = "Depression Ever (Yes/No)",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
datagroup_var <- combined_data |>
ggplot(aes(x = reorder(data_group, -table(data_group)[data_group]), fill = data_group)) +
geom_bar() +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, size = 3) +
labs(
title = "Distribution of Data Group",
x = "Data Group",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
# Save combined dataset ----
save(target_var, datagroup_var, file = here("data_combined/dist_barplots.rda"))
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
library(knitr)
load(here("data_combined/dist_barplot.rda"))
#| echo: FALSE
library(tidyverse)
library(tidymodels)
library(here)
library(knitr)
load(here("data_combined/dist_barplots.rda"))
load(here("attempt_1/results/metric_results_a.rda"))
load(here("attempt_2/results/metric_results_b.rda"))
#| label: fig-dist
#| fig-cap: "Distribution of Target Variable"
#| echo: false
target_var
#| label: fig-dist1
#| fig-cap: "Distribution of Focus Group"
#| echo: false
datagroup_var
?vfold_cv()
# data splitting
# load packages ----
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(janitor)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
combined_data <- read_csv(here("data_combined/combined_nhis_data.csv"))
# data split
data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
# data splitting
# load packages ----
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(janitor)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
combined_data <- read_csv(here("data_combined/combined_nhis_data.csv"))
# data split
data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
data_fold <- vfold_cv(data_train, v = 5,
strata = depression_ever)
save(data_split, data_train, data_test, data_fold, file = here("attempt_2/results/data_split.rda"))
# data splitting
# load packages ----
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(janitor)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
combined_data <- read_csv(here("data_combined/combined_nhis_data.csv"))
# data split
data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
data_fold <- vfold_cv(data_train, v = 5, repeats = 3,
strata = depression_ever)
save(data_split, data_train, data_test, data_fold, file = here("attempt_3/results/data_split.rda"))
# data splitting
# load packages ----
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(janitor)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
combined_data <- read_csv(here("data_combined/combined_nhis_data.csv"))
# data split
data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
data_fold <- vfold_cv(data_train, v = 5, repeats = 3,
strata = depression_ever)
save(data_split, data_train, data_test, data_fold, file = here("attempt_3/results/data_split.rda"))
View(combined_data)
View(combined_data)
m3_recipe <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
# Setup pre-processing/recipes - M1 just groups
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_3/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# M3 recipe - (m1 + m2) + tertiary factors
## for non tree (parametric) models
m3_recipe <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
## for  tree (non-parametric) models
m3_recipe_t <- recipe(epression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
# Remove other unnecessary variables
#step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
# Setup pre-processing/recipes - M3 just groups
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_3/results/data_split.rda"))
# Setup pre-processing/recipes - M3 just groups
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_3/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# M3 recipe - (m1 + m2) + tertiary factors
## for non tree (parametric) models
m3_recipe <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
prep(m3_recipe) |>
bake(new_data = NULL)
## for  tree (non-parametric) models
m3_recipe_t <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
# Remove other unnecessary variables
#step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
prep(m3_recipe_t) |>
bake(new_data = NULL)
save(m3_recipe, m3_recipe_t, file = here("attempt_3/recipes/m3_recipes.rda"))
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_3/results/data_split.rda"))
load(here("attempt_3/recipes/m3_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(m3_recipe)
# fit workflows/models ----
logistic_fit_c <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit_c, file = "attempt_3/results/c_logistic_fit.rda")
# decision tree
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# Handle common conflicts
tidymodels_prefer()
# Set seed
set.seed(301)
# Load preprocessed data and recipe ----
load(here("attempt_3/results/data_split.rda"))
load(here("attempt_3/recipes/m3_recipes.rda"))
# Enable parallel processing ----
library(doMC)
registerDoMC(cores = parallel::detectCores(logical = TRUE))
# Model specifications ----
dtree_model <-
decision_tree(
mode = "classification",
cost_complexity = tune(),   # Controls pruning
tree_depth = tune(),        # Max depth of tree
min_n = tune()              # Minimum samples required for a split
) |>
set_engine("rpart")           # Use the rpart engine
# Define workflow ----
dtree_workflow <- workflow() |>
add_model(dtree_model) |>
add_recipe(m3_recipe_t)
dtree_params <- extract_parameter_set_dials(dtree_model)
dtree_grid <- grid_regular(dtree_params, levels = 5)
dtree_fit_c <- tune_grid(
dtree_workflow,
resamples = data_fold,        # Assuming `data_fold` is your cross-validation folds
grid = dtree_grid,
control = control_grid(save_workflow = TRUE)
)
# naive bayes
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(discrim)
# Handle common conflicts
tidymodels_prefer()
# Set seed
set.seed(301)
# Load preprocessed data and recipe ----
load(here("attempt_3/results/data_split.rda"))
load(here("attempt_3/recipes/m3_recipes.rda"))
# Enable parallel processing ----
library(doMC)
registerDoMC(cores = parallel::detectCores(logical = TRUE))
# Model specifications ----
nbayes_model <-
naive_Bayes(
mode = "classification",
smoothness = tune(), # Hyperparameter for Laplace smoothing
Laplace = tune()     # Additional smoothing parameter
) |>
set_engine("klaR")      # Ensure 'klaR' package is installed
# Define workflow ----
nbayes_workflow <- workflow() |>
add_model(nbayes_model) |>
add_recipe(m3_recipe)
# Hyperparameter tuning values ----
nbayes_params <- extract_parameter_set_dials(nbayes_model)
# Create grid for tuning ----
nbayes_grid <- grid_regular(nbayes_params, levels = 5)
# Fit workflows/models ----
nbayes_fit_c <- tune_grid(
nbayes_workflow,
resamples = data_fold, # Assuming `data_fold` is your cross-validation folds
grid = nbayes_grid,
control = control_grid(save_workflow = TRUE)
)
# RuleFit
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(xrf)
library(rules)
# Handle common conflicts
tidymodels_prefer()
# Set seed
set.seed(301)
# Load preprocessed data and recipe ----
load(here("attempt_3/results/data_split.rda"))
load(here("attempt_3/recipes/m1_recipes.rda"))
# RuleFit
# Load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(xrf)
library(rules)
# Handle common conflicts
tidymodels_prefer()
# Set seed
set.seed(301)
# Load preprocessed data and recipe ----
load(here("attempt_3/results/data_split.rda"))
load(here("attempt_3/recipes/m3_recipes.rda"))
# Enable parallel processing ----
library(doMC)
registerDoMC(cores = parallel::detectCores(logical = TRUE))
# Set RuleFit model specification
rulefit_model <- rule_fit(
mode = "classification",
penalty = tune()
) |>
set_engine("xrf")
rulefit_workflow <- workflow() |>
add_model(rulefit_model) |>
add_recipe(m3_recipe_t)
rulefit_params <- extract_parameter_set_dials(rulefit_model)
rulefit_grid <- grid_regular(rulefit_params, levels = 5)
rulefit_fit_c <- tune_grid(
rulefit_workflow,
resamples = data_fold, # `data_fold` is my cross-validation folds
grid = rulefit_grid,
control = control_grid(save_workflow = TRUE)
)
