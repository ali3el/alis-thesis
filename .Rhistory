data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
data_fold <- vfold_cv(data_train, v = 4, repeats = 3,
strata = depression_ever)
save(data_split, data_train, data_test, data_fold, file = here("attempt_1/results/data_split.rda"))
# Setup pre-processing/recipes - KITCHEN SINK
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_1/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# kitchen sink recipe
## for non tree (parametric) models
ks_recipe <- recipe(depression_ever ~ ., data = data_train) |>
step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
prep(ks_recipe) |>
bake(new_data = NULL)
## for  tree (non-parametric) models
ks_recipe_t <- recipe(depression_ever ~ ., data = data_train) |>
# Remove other unnecessary variables
step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
prep(ks_recipe_t) |>
bake(new_data = NULL)
save(ks_recipe, ks_recipe_t, file = "attempt_1/recipes/ks_recipes.rda")
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_1/results/data_split.rda"))
load(here("attempt_1/recipes/ks_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(ks_recipe)
# fit workflows/models ----
logistic_fit <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit, file = "attempt_1/results/a_logistic_fit.rda")
gc()
gc()
gc()
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_1/results/data_split.rda"))
load(here("attempt_1/recipes/ks_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(ks_recipe)
# fit workflows/models ----
logistic_fit <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit, file = "attempt_1/results/a_logistic_fit.rda")
gc()
# Setup pre-processing/recipes - M2 just groups
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_2/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# M2 recipe - just groups
## for non tree (parametric) models
m2_recipe <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details,
data = data_train) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
prep(m2_recipe) |>
bake(new_data = NULL)
## for  tree (non-parametric) models
m2_recipe_t <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details,
data = data_train) |>
# Remove other unnecessary variables
#step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
prep(m2_recipe_t) |>
bake(new_data = NULL)
save(m2_recipe, m2_recipe_t, file = here("attempt_2/recipes/m2_recipes.rda"))
gc()
gc()
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_2/results/data_split.rda"))
load(here("attempt_2/recipes/m2_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(m2_recipe)
# fit workflows/models ----
logistic_fit_b <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit_b, file = "attempt_2/results/b_logistic_fit.rda")
gc()
gc()
# data splitting
# load packages ----
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
library(janitor)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
combined_data <- read_csv(here("data_combined/combined_nhis_data.csv"))
# data split
data_split <- initial_split(combined_data,
prop = 0.80,
strat = depression_ever,
breaks = 4)
data_train <- data_split |> training()
data_test <- data_split |> testing()
data_fold <- vfold_cv(data_train, v = 4, repeats = 3,
strata = depression_ever)
save(data_split, data_train, data_test, data_fold, file = here("attempt_3/results/data_split.rda"))
# Setup pre-processing/recipes - M3 just groups
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
load(here("attempt_3/results/data_split.rda"))
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# M3 recipe - (m1 + m2) + tertiary factors
## for non tree (parametric) models
m3_recipe <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
# Convert nominal predictors to dummy variables
step_dummy(all_nominal_predictors()) |>
# Remove zero-variance predictors
step_zv(all_predictors()) |>
# Normalize predictors
step_normalize(all_predictors())
prep(m3_recipe) |>
bake(new_data = NULL)
## for  tree (non-parametric) models
m3_recipe_t <- recipe(depression_ever ~ data_group + region + urban_rural + race_category +
age + sex + hispanic_ethnicity + hispanic_and_race + hispanic_details +
education_level + max_education_level + not_covered + marital_status +
parent_status,
data = data_train) |>
# Remove other unnecessary variables
#step_rm(year) |>
step_impute_mode(all_nominal_predictors()) |>  # For categorical variables
step_impute_median(all_numeric_predictors()) |>  # For numeric variables
step_novel(all_nominal_predictors()) |>
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
step_zv(all_predictors()) |>
step_normalize(all_predictors())
prep(m3_recipe_t) |>
bake(new_data = NULL)
save(m3_recipe, m3_recipe_t, file = here("attempt_3/recipes/m3_recipes.rda"))
# Logistic Regression
# # load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
load(here("attempt_3/results/data_split.rda"))
load(here("attempt_3/recipes/m3_recipes.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# model specifications ----
logistic_model <- logistic_reg() |>
set_engine("glm") |>
set_mode("classification")
# define workflows ----
logistic_workflow <- workflow() |>
add_model(logistic_model) |>
add_recipe(m3_recipe)
# fit workflows/models ----
logistic_fit_c <- fit_resamples(logistic_workflow,
resamples = data_fold,
control = control_resamples(
save_workflow = TRUE,
parallel_over = "everything"))
# when tuning we need to make a grid
# write out results (fitted/trained workflows) ----
save(logistic_fit_c, file = "attempt_3/results/c_logistic_fit.rda")
gc()
gc()
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_3/results/data_split.rda"))
load(here("attempt_3/recipes/m3_recipes.rda"))
load(here("attempt_3/results/c_logistic_fit.rda"))
load(here("attempt_3/results/c_dtree_fit.rda"))
load(here("attempt_3/results/c_nbayes_fit.rda"))
load(here("attempt_3/results/c_knn_fit.rda"))
load(here("attempt_3/results/c_rulefit_fit.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# results
logistic_result <- collect_metrics(logistic_fit_c) |>
mutate(model = "logistic")
logistic_result
dtree_result <- collect_metrics(dtree_fit_c) |>
mutate(model = "decision tree")
dtree_result
knn_result <- collect_metrics(knn_fit_c) |>
mutate(model = "KNN")
knn_result
nbayes_result <- collect_metrics(nbayes_fit_c) |>
mutate(model = "Naive Bayes")
nbayes_result
rulefit_result <- collect_metrics(rulefit_fit_c) |>
mutate(model = "RuleFit")
rulefit_result
log_c_acc <- logistic_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Logistic M3")
dtree_c_acc <- dtree_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Decision Tree M3")
knn_c_acc <- knn_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "KNN M3")
nbayes_c_acc <- nbayes_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Naive Bayes M3")
rulefit_c_acc <- rulefit_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "RuleFit M3")
table_c_accuracy <- bind_rows(log_c_acc, dtree_c_acc, knn_c_acc, nbayes_c_acc, rulefit_c_acc) |>
select(model, mean, std_err, n) |>
arrange(mean) |>
distinct()
table_c_accuracy
dtree_autoplot_c <- autoplot(dtree_fit_c, metric = "accuracy")
knn_autoplot_c <- autoplot(knn_fit_c, metric = "accuracy")
rulefit_autoplot_c <- autoplot(rulefit_fit_c, metric = "accuracy")
# nbayes_autoplot_a <- autoplot(nbayes_fit, metric = "accuracy")
save(table_c_accuracy, dtree_autoplot_c,
knn_autoplot_c, rulefit_autoplot_c,
file = here("attempt_3/results/metric_results_c.rda"))
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_2/results/data_split.rda"))
load(here("attempt_2/recipes/m2_recipes.rda"))
load(here("attempt_2/results/b_logistic_fit.rda"))
load(here("attempt_2/results/b_dtree_fit.rda"))
load(here("attempt_2/results/b_nbayes_fit.rda"))
load(here("attempt_2/results/b_knn_fit.rda"))
load(here("attempt_2/results/b_rulefit_fit.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# results
logistic_result <- collect_metrics(logistic_fit_b) |>
mutate(model = "logistic")
logistic_result
dtree_result <- collect_metrics(dtree_fit_b) |>
mutate(model = "decision tree")
dtree_result
knn_result <- collect_metrics(knn_fit_b) |>
mutate(model = "KNN")
knn_result
nbayes_result <- collect_metrics(nbayes_fit_b) |>
mutate(model = "Naive Bayes")
nbayes_result
rulefit_result <- collect_metrics(rulefit_fit_b) |>
mutate(model = "RuleFit")
rulefit_result
log_b_acc <- logistic_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Logistic M2")
dtree_b_acc <- dtree_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Decision Tree M2")
knn_b_acc <- knn_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "KNN M2")
nbayes_b_acc <- nbayes_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Naive Bayes M2")
rulefit_b_acc <- rulefit_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "RuleFit M2")
table_b_accuracy <- bind_rows(log_b_acc, dtree_b_acc, knn_b_acc, nbayes_b_acc, rulefit_b_acc) |>
select(model, mean, std_err, n) |>
arrange(mean) |>
distinct()
table_b_accuracy
dtree_autoplot_b <- autoplot(dtree_fit_b, metric = "accuracy")
knn_autoplot_b <- autoplot(knn_fit_b, metric = "accuracy")
rulefit_autoplot_b <- autoplot(rulefit_fit_b, metric = "accuracy")
# nbayes_autoplot_a <- autoplot(nbayes_fit, metric = "accuracy")
save(table_b_accuracy, dtree_autoplot_b,
knn_autoplot_b, rulefit_autoplot_b,
file = here("attempt_2/results/metric_results_b.rda"))
table_b_accuracy
table_c_accuracy
# Analysis of trained models (comparisons)
# Select final model
# Fit & analyze final model
# load packages ----
library(tidyverse)
library(tidymodels)
library(here)
# handle common conflicts
tidymodels_prefer()
# set seed
set.seed(301)
# load data, recipes and fits
load(here("attempt_1/results/data_split.rda"))
load(here("attempt_1/recipes/ks_recipes.rda"))
load(here("attempt_1/results/a_logistic_fit.rda"))
load(here("attempt_1/results/a_dtree_fit.rda"))
load(here("attempt_1/results/a_nbayes_fit.rda"))
load(here("attempt_1/results/a_knn_fit.rda"))
load(here("attempt_1/results/a_rulefit_fit.rda"))
library(doMC)
registerDoMC(cores = parallel::detectCores(logical =TRUE))
# results
logistic_result <- collect_metrics(logistic_fit) |>
mutate(model = "logistic")
logistic_result
dtree_result <- collect_metrics(dtree_fit) |>
mutate(model = "decision tree")
dtree_result
knn_result <- collect_metrics(knn_fit) |>
mutate(model = "KNN")
knn_result
nbayes_result <- collect_metrics(nbayes_fit) |>
mutate(model = "Naive Bayes")
nbayes_result
rulefit_result <- collect_metrics(rulefit_fit) |>
mutate(model = "RuleFit")
rulefit_result
log_a_acc <- logistic_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Logistic KS")
dtree_a_acc <- dtree_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Decision Tree KS")
knn_a_acc <- knn_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "KNN KS")
nbayes_a_acc <- nbayes_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "Naive Bayes KS")
rulefit_a_acc <- rulefit_result |>
filter(.metric == "accuracy") |>
slice_max(mean) |>
select(mean, n, std_err) |>
mutate(model = "RuleFit KS")
table_a_accuracy <- bind_rows(log_a_acc, dtree_a_acc, knn_a_acc, nbayes_a_acc, rulefit_a_acc) |>
select(model, mean, std_err, n) |>
arrange(mean) |>
distinct()
table_a_accuracy
dtree_autoplot_a <- autoplot(dtree_fit, metric = "accuracy")
knn_autoplot_a <- autoplot(knn_fit, metric = "accuracy")
rulefit_autoplot_a <- autoplot(rulefit_fit, metric = "accuracy")
# nbayes_autoplot_a <- autoplot(nbayes_fit, metric = "accuracy")
save(table_a_accuracy, dtree_autoplot_a,
knn_autoplot_a, rulefit_autoplot_a,
file = here("attempt_1/results/metric_results_a.rda"))
table_a_accuracy
table_b_accuracy
table_c_accuracy
